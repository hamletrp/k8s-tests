
pre-requisites 
  AMIS 
    aws ssm get-parameters-by-path \
    --path /aws/service/eks/optimized-ami/1.28/amazon-linux-2/recommended \
    --region us-west-2

  aws iam create-service-linked-role --aws-service-name spot.amazonaws.com || true
  # AWSServiceRoleForAmazonEKS
  or 
  set the EC2NodeClass
    role: eksctl-cluster-lab-10-nodegroup-linu-NodeInstanceRole


dependent resources stack 
  deployed via terraform
    karpenter-dependencies.yaml 
    https://raw.githubusercontent.com/aws/karpenter-provider-aws/v1.0.10/website/content/en/preview/getting-started/getting-started-with-karpenter/cloudformation.yaml


set env vars
  export CLUSTER_NAME="cluster-lab-10" && \
  export KARPENTER_NAMESPACE="karpenter" && \
  export KARPENTER_VERSION=1.5.0 && \
  export KARPENTER_IAM_ROLE_ARN="arn:aws:iam::722249351142:role/KarpenterControllerRole-cluster-lab-10" \
  export INTERRUPTION_QUEUE_NAME="karpenter-interruption-queue-cluster-lab-10"


---
  --set controller.autoscaling.enabled=true \
  --set controller.autoscaling.minReplicas=2 \
  --set controller.autoscaling.maxReplicas=5 \
  --set serviceAccount.name=karpenter \
---


self-signed cert setup 
  run cert-manager steps.txt
  k delete -f ./gitops/karpenter/issuer.yaml
  k apply -f ./gitops/karpenter/issuer.yaml

  k delete -f ./gitops/karpenter/certificate.yaml
  k apply -f ./gitops/karpenter/certificate.yaml
 k -n karpenter get secret karpenter-cert -o jsonpath="{.data}"

  k delete -f ./gitops/karpenter/karpenter-webhook-tls.yaml
  k apply -f ./gitops/karpenter/karpenter-webhook-tls.yaml
  k -n karpenter get secret karpenter-webhook-tls -o jsonpath="{.data}"


    k apply -f ./gitops/karpenter/karpenter-argocdapp.yaml
    k apply -f ./gitops/karpenter-root/karpenter-root-app.yaml

---
helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version ${KARPENTER_VERSION} --namespace "${KARPENTER_NAMESPACE}" --create-namespace \
  --set "settings.clusterName=${CLUSTER_NAME}" \
  --set "settings.interruptionQueue=${INTERRUPTION_QUEUE_NAME}" \
  --set controller.resources.requests.cpu=1 \
  --set controller.resources.requests.memory=1Gi \
  --set controller.resources.limits.cpu=1 \
  --set controller.resources.limits.memory=1Gi \
  --set controller.replicas=2 \
  --set "serviceAccount.annotations.eks\.amazonaws\.com/role-arn=${KARPENTER_IAM_ROLE_ARN}" 
  
  apply node class 
    k apply -f ./gitops/karpenter/ec2-nodeclass-default.yaml

  force delete nodeclass 
    kubectl patch ec2nodeclass default -n karpenter -p '{"metadata":{"finalizers":[]}}' --type=merge

  apply node pool 
    k apply -f ./gitops/karpenter/nodepool-def-allinstance.yaml


---

  interruptionQueue update sample
    helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
      --namespace "${KARPENTER_NAMESPACE}" --create-namespace \
      --version "${KARPENTER_VERSION}" \
      --set controller.interruptionQueue=https://sqs.us-east-1.amazonaws.com/722249351142/karpenter-interruption-queue-cluster-lab-10

---

k create deploy stress --image=busybox --replicas=350 -- sleep 3600
k scale deploy stress --replicas 600
k delete deploy stress

---

kubectl get nodes -o json | jq '.items[].spec.taints'


kubectl get pods -n default --field-selector=status.phase!=Running -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'

kubectl patch pod stress-no-tolerations-89f44dd88-ztn9g -n default --type='json' -p='[{"op": "add", "path": "/spec/tolerations/-", "value": {"key": "karpenter.sh/capacity-type", "operator": "Equal", "value": "spot", "effect": "NoSchedule"}}]'


---



k get all -n karpenter -l app.kubernetes.io/name=karpenter

k get pods -n karpenter -l app.kubernetes.io/name=karpenter

k -n karpenter logs pod/karpenter-5f4bf97fb5-ddlbl
k -n karpenter logs pod/karpenter-5f4bf97fb5-fbg8x

k rollout restart deployment.apps/karpenter -n karpenter
or specific pods 
kubectl get pods -n default --field-selector=status.phase!=Running -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' \
  | xargs -n1 -I{} kubectl delete pod {} -n default

k -n karpenter get pod karpenter-74cdcffcd5-gqvkf -o yaml > ./poda.yaml

k -n karpenter delete pod/karpenter-75bfbf8cfc-68s9r

k logs -n karpenter -l app.kubernetes.io/name=karpenter -c controller

curl http://169.254.169.254/latest/meta-data/iam/info


---
 helm uninstall karpenter -n karpenter  
---

cat <<EOF | envsubst | k apply -f -
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  template:
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r"]
        - key: karpenter.k8s.aws/instance-generation
          operator: Gt
          values: ["2"]
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: default
      expireAfter: 720h # 30 * 24h = 720h
  limits:
    cpu: 1000
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 1m
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2 # Amazon Linux 2
  role: "KarpenterNodeRole-${CLUSTER_NAME}" # replace with your cluster name
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}" # replace with your cluster name
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}" # replace with your cluster name
  amiSelectorTerms:
    - id: "${ARM_AMI_ID}"
    - id: "${AMD_AMI_ID}"
#   - id: "${GPU_AMI_ID}" # <- GPU Optimized AMD AMI 
#   - name: "amazon-eks-node-${K8S_VERSION}-*" # <- automatically upgrade when a new AL2 EKS Optimized AMI is released. This is unsafe for production workloads. Validate AMIs in lower environments before deploying them to production.
EOF



aws eks describe-cluster \
  --name cluster-lab-10 \
  --region us-east-1 \
  --query "cluster.endpoint" \
  --output text

--- 

cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: inflate
spec:
  replicas: 0
  selector:
    matchLabels:
      app: inflate
  template:
    metadata:
      labels:
        app: inflate
    spec:
      terminationGracePeriodSeconds: 0
      securityContext:
        runAsUser: 1000
        runAsGroup: 3000
        fsGroup: 2000
      containers:
      - name: inflate
        image: public.ecr.aws/eks-distro/kubernetes/pause:3.7
        resources:
          requests:
            cpu: 1
        securityContext:
          allowPrivilegeEscalation: false
EOF

kubectl scale deployment inflate --replicas 370

