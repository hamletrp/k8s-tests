
pre-requisites 
  aws iam create-service-linked-role --aws-service-name spot.amazonaws.com || true
  # AWSServiceRoleForAmazonEKS

set env vars
  export CLUSTER_NAME="cluster-lab-3" && \
  export KARPENTER_NAMESPACE="kube-system" && \
  export KARPENTER_VERSION="1.0.10" && \
  export KARPENTER_IAM_ROLE_ARN="arn:aws:iam::722249351142:role/KarpenterControllerRole-cluster-lab-3"
  export INTERRUPTION_QUEUE_NAME="karpenter-interruption-queue-cluster-lab-3"


helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter --version "${KARPENTER_VERSION}" --namespace "${KARPENTER_NAMESPACE}" --create-namespace \
  --set "settings.clusterName=${CLUSTER_NAME}" \
  --set "settings.interruptionQueue=${INTERRUPTION_QUEUE_NAME}" \
  --set controller.resources.requests.cpu=1 \
  --set controller.resources.requests.memory=1Gi \
  --set controller.resources.limits.cpu=1 \
  --set controller.resources.limits.memory=1Gi \
  --set "serviceAccount.annotations.eks\.amazonaws\.com/role-arn=${KARPENTER_IAM_ROLE_ARN}" 
  
  
  --set controller.interruptionQueue=https://sqs.us-east-1.amazonaws.com/722249351142/karpenter-interruption-queue-cluster-lab-3
  --wait

  interruptionQueue update 
    helm upgrade --install karpenter oci://public.ecr.aws/karpenter/karpenter \
      --namespace "${KARPENTER_NAMESPACE}" --create-namespace \
      --version "${KARPENTER_VERSION}" \
      --set controller.interruptionQueue=https://sqs.us-east-1.amazonaws.com/722249351142/karpenter-interruption-queue-cluster-lab-3

---

k get all -n kube-system -l app.kubernetes.io/name=karpenter

k get pods -n kube-system -l app.kubernetes.io/name=karpenter

k -n kube-system logs pod/karpenter-866b97c754-rxkwl
k -n kube-system logs pod/karpenter-866b97c754-wb9dm

k rollout restart deployment.apps/karpenter -n kube-system

k -n kube-system get pod karpenter-74cdcffcd5-gqvkf -o yaml > ./poda.yaml

k -n kube-system delete pod/karpenter-75bfbf8cfc-68s9r

k logs -n kube-system -l app.kubernetes.io/name=karpenter -c controller


cat <<EOF | envsubst | k apply -f -
apiVersion: karpenter.sh/v1
kind: NodePool
metadata:
  name: default
spec:
  template:
    spec:
      requirements:
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: karpenter.k8s.aws/instance-category
          operator: In
          values: ["c", "m", "r"]
        - key: karpenter.k8s.aws/instance-generation
          operator: Gt
          values: ["2"]
      nodeClassRef:
        group: karpenter.k8s.aws
        kind: EC2NodeClass
        name: default
      expireAfter: 720h # 30 * 24h = 720h
  limits:
    cpu: 1000
  disruption:
    consolidationPolicy: WhenEmptyOrUnderutilized
    consolidateAfter: 1m
---
apiVersion: karpenter.k8s.aws/v1
kind: EC2NodeClass
metadata:
  name: default
spec:
  amiFamily: AL2 # Amazon Linux 2
  role: "KarpenterNodeRole-${CLUSTER_NAME}" # replace with your cluster name
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}" # replace with your cluster name
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: "${CLUSTER_NAME}" # replace with your cluster name
  amiSelectorTerms:
    - id: "${ARM_AMI_ID}"
    - id: "${AMD_AMI_ID}"
#   - id: "${GPU_AMI_ID}" # <- GPU Optimized AMD AMI 
#   - name: "amazon-eks-node-${K8S_VERSION}-*" # <- automatically upgrade when a new AL2 EKS Optimized AMI is released. This is unsafe for production workloads. Validate AMIs in lower environments before deploying them to production.
EOF



aws eks describe-cluster \
  --name cluster-lab-3 \
  --region us-east-1 \
  --query "cluster.endpoint" \
  --output text